{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://medium.com/@tarekseif0/document-similarity-using-word-movers-distance-and-cosine-similarity-d698ad435422"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "import json\n",
    "from rake_nltk import Rake\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk import word_tokenize, pos_tag\n",
    "from pyemd import emd\n",
    "# from gensim.similarities import WmdSimilarity\n",
    "\n",
    "\n",
    "# Load pretrained model (since intermediate data is not included, the model cannot be refined with additional data)\n",
    "# model = Word2Vec.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True, norm_only=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin.gz', binary=True) #without *norm_only* param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dog = model['dog']\n",
    "# print(dog.shape)\n",
    "# print(dog[:10])\n",
    "\n",
    "# # Deal with an out of dictionary word: Михаил (Michail)\n",
    "# # if 'Михаил' in model:\n",
    "# #     print(model['Михаил'].shape)\n",
    "# # else:\n",
    "# #     print('{0} is an out of dictionary word'.format('Михаил'))\n",
    "\n",
    "# # Some predefined functions that show content related information for given words\n",
    "# print(model.most_similar(positive=['woman', 'king'], negative=['man']))\n",
    "\n",
    "# # print(model.doesnt_match(\"breakfast cereal dinner lunch\".split()))\n",
    "\n",
    "# # print(model.similarity('woman', 'man'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers1 = []\n",
    "f = open('answers1.txt')\n",
    "lines = f.readlines()\n",
    "\n",
    "for line in lines:\n",
    "    if line!='\\n':\n",
    "        answers1 += [line.replace('\\n', '')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data type before reconstruction :  <class 'str'>\n",
      "Data type after reconstruction :  <class 'list'>\n"
     ]
    }
   ],
   "source": [
    "with open('model_answers.txt') as f: \n",
    "    data = f.read() \n",
    "  \n",
    "print(\"Data type before reconstruction : \", type(data)) \n",
    "      \n",
    "# reconstructing the data as a dictionary \n",
    "model_answer_list = json.loads(data) \n",
    "  \n",
    "print(\"Data type after reconstruction : \", type(model_answer_list)) \n",
    "# print(model_answer_list) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Enhance the responsiveness to the users.': 0.5, 'Resource sharing within the process.': 0.5, 'Economical': 0.5, 'Completely utilize the multiprocessing architecture.': 0.5}\n",
      "Responsiveness, Resource Sharing, Economy, Scalability\n"
     ]
    }
   ],
   "source": [
    "model_answer = model_answer_list[-2]\n",
    "student_answer =  answers1[-2]\n",
    "\n",
    "print(model_answer)\n",
    "print(student_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def penn_to_wn(tag):\n",
    "    \"\"\" Convert between a Penn Treebank tag to a simplified Wordnet tag \"\"\"\n",
    "    if tag.startswith('N'):\n",
    "        return 'n'\n",
    " \n",
    "    if tag.startswith('V'):\n",
    "        return 'v'\n",
    " \n",
    "    if tag.startswith('J'):\n",
    "        return 'a'\n",
    " \n",
    "    if tag.startswith('R'):\n",
    "        return 'r'\n",
    " \n",
    "    return 'n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_similarity(model_key, student_key):\n",
    "    lemmatizer = WordNetLemmatizer() \n",
    "\n",
    "    model_answer_tokenized = word_tokenize(model_key)\n",
    "    model_pos_tagged = pos_tag(model_answer_tokenized)\n",
    "#     print(model_pos_tagged)\n",
    "    model_tagged = [lemmatizer.lemmatize(word[0].lower(),penn_to_wn(word[1])) for word in model_pos_tagged]\n",
    "\n",
    "    student_answer_tokenized = word_tokenize(student_key)\n",
    "    student_pos_tagged = pos_tag(student_answer_tokenized)\n",
    "#     print(student_pos_tagged)\n",
    "    student_tagged = [lemmatizer.lemmatize(word[0].lower(),penn_to_wn(word[1])) for word in student_pos_tagged]\n",
    "    \n",
    "#     print(model_tagged,student_tagged)\n",
    "    return model.wmdistance(model_tagged, student_tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = Rake()\n",
    "model.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['resource sharing', 'scalability', 'responsiveness', 'economy']\n"
     ]
    }
   ],
   "source": [
    "r.extract_keywords_from_text(student_answer)\n",
    "student_keywords = r.get_ranked_phrases()\n",
    "print(student_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['users', 'responsiveness', 'enhance']\n",
      "users , scalability , 1.150754690170288\n",
      "responsiveness , responsiveness , 0.0\n",
      "enhance , responsiveness , 1.200353741645813\n",
      "0.7837028106053671\n",
      "['resource sharing within', 'process']\n",
      "resource sharing within , resource sharing , 0.802683166236407\n",
      "process , responsiveness , 1.2708280086517334\n",
      "1.0367555874440701\n",
      "['economical']\n",
      "economical , scalability , 1.2102012634277344\n",
      "1.2102012634277344\n",
      "['multiprocessing architecture', 'completely utilize']\n",
      "multiprocessing architecture , scalability , 1.0290510912954807\n",
      "completely utilize , resource sharing , 1.3271456892656088\n",
      "1.1780983902805446\n"
     ]
    }
   ],
   "source": [
    "for sentence in model_answer.keys():\n",
    "    sum = 0\n",
    "    r.extract_keywords_from_text(sentence)\n",
    "    sentence_keywords = r.get_ranked_phrases()\n",
    "    print(sentence_keywords)\n",
    "#     print(sentence_keyword,\",\",student_keyword,\",\",sentence_similarity(sentence_keyword, student_keyword))\n",
    "    for sentence_keyword in sentence_keywords:\n",
    "        best = None\n",
    "        match = None\n",
    "        for student_keyword in student_keywords:\n",
    "#             print(student_keyword)\n",
    "#             print(lemmatizer.lemmatize([x for x in word_tokenize(sentence_keyword)]))\n",
    "#             print(sentence_keyword,\",\",student_keyword,\",\",sentence_similarity(sentence_keyword, student_keyword))\n",
    "            sim = sentence_similarity(sentence_keyword, student_keyword)\n",
    "            if best is None:\n",
    "                best = sim\n",
    "                match = student_keyword\n",
    "            elif sim<best:\n",
    "                best = sim\n",
    "                match = student_keyword\n",
    "        sum += best\n",
    "        print(sentence_keyword,\",\",match,\",\", best)\n",
    "    print(sum/len(sentence_keywords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from gensim.similarities import WmdSimilarity\n",
    "# lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_best = 10\n",
    "# instance = WmdSimilarity(student_keywords, model, num_best=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for sentence in model_answer.keys():\n",
    "#     r.extract_keywords_from_text(sentence)\n",
    "#     sentence_keywords = r.get_ranked_phrases()\n",
    "#     for sentence_keyword in sentence_keywords:\n",
    "#         sentence_keyword_tokenized = word_tokenize(sentence_keyword)\n",
    "#         sentence_keyword_pos_tagged = pos_tag(sentence_keyword_tokenized)\n",
    "#         sentence_keyword_tagged = [lemmatizer.lemmatize(word[0].lower(),penn_to_wn(word[1])) for word in sentence_keyword_pos_tagged]\n",
    "#         sims = instance[sentence_keyword_tagged]\n",
    "#         print(sentence_keyword_tagged)\n",
    "#         for i in range(len(sims)):\n",
    "#             print ('sim = %.4f' % sims[i][1])\n",
    "#             print(student_keywords[sims[i][0]])\n",
    "# #         for student_keyword in student_keywords:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing average similarity of all answers with one-another"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "import json\n",
    "from rake_nltk import Rake\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk import word_tokenize, pos_tag\n",
    "from pyemd import emd\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin.gz', binary=True) #without *norm_only* param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers1 = []\n",
    "f = open('answers2.txt',encoding='utf-8')\n",
    "lines = f.readlines()\n",
    "\n",
    "for line in lines:\n",
    "    if line!='\\n':\n",
    "        answers1 += [line.replace('\\n', '')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data type before reconstruction :  <class 'str'>\n",
      "Data type after reconstruction :  <class 'list'>\n"
     ]
    }
   ],
   "source": [
    "with open('model_answers.txt') as f: \n",
    "    data = f.read() \n",
    "  \n",
    "print(\"Data type before reconstruction : \", type(data)) \n",
    "      \n",
    "# reconstructing the data as a dictionary \n",
    "model_answer_list = json.loads(data) \n",
    "  \n",
    "print(\"Data type after reconstruction : \", type(model_answer_list)) \n",
    "# print(model_answer_list) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def penn_to_wn(tag):\n",
    "    \"\"\" Convert between a Penn Treebank tag to a simplified Wordnet tag \"\"\"\n",
    "    if tag.startswith('N'):\n",
    "        return 'n'\n",
    " \n",
    "    if tag.startswith('V'):\n",
    "        return 'v'\n",
    " \n",
    "    if tag.startswith('J'):\n",
    "        return 'a'\n",
    " \n",
    "    if tag.startswith('R'):\n",
    "        return 'r'\n",
    " \n",
    "    return 'n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_similarity(model_key, student_key):\n",
    "    lemmatizer = WordNetLemmatizer() \n",
    "\n",
    "    model_answer_tokenized = word_tokenize(model_key)\n",
    "    model_pos_tagged = pos_tag(model_answer_tokenized)\n",
    "    model_tagged = [lemmatizer.lemmatize(word[0].lower(),penn_to_wn(word[1])) for word in model_pos_tagged]\n",
    "\n",
    "    student_answer_tokenized = word_tokenize(student_key)\n",
    "    student_pos_tagged = pos_tag(student_answer_tokenized)\n",
    "    student_tagged = [lemmatizer.lemmatize(word[0].lower(),penn_to_wn(word[1])) for word in student_pos_tagged]\n",
    "    \n",
    "#     print(model_tagged,student_tagged)\n",
    "    return model.wmdistance(model_tagged, student_tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 3.35 GiB for an array with shape (3000000, 300) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-572ef0279972>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit_sims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\sarika\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36minit_sims\u001b[1;34m(self, replace)\u001b[0m\n\u001b[0;32m   1352\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'vectors_norm'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mreplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1353\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"precomputing L2-norms of word weight vectors\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1354\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvectors_norm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_l2_norm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvectors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1355\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1356\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrelative_cosine_similarity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwa\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtopn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sarika\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36m_l2_norm\u001b[1;34m(m, replace)\u001b[0m\n\u001b[0;32m   2382\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2383\u001b[0m     \"\"\"\n\u001b[1;32m-> 2384\u001b[1;33m     \u001b[0mdist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m \u001b[1;33m**\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m...\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewaxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2385\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mreplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2386\u001b[0m         \u001b[0mm\u001b[0m \u001b[1;33m/=\u001b[0m \u001b[0mdist\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 3.35 GiB for an array with shape (3000000, 300) and data type float32"
     ]
    }
   ],
   "source": [
    "r = Rake()\n",
    "model.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(student_answer, model_answer):\n",
    "    r.extract_keywords_from_text(student_answer)\n",
    "    student_keywords = r.get_ranked_phrases()\n",
    "#     print(student_keywords)\n",
    "    marks = 0\n",
    "    for sentence in model_answer.keys():\n",
    "        sum = 0\n",
    "        r.extract_keywords_from_text(sentence)\n",
    "        sentence_keywords = r.get_ranked_phrases()\n",
    "#         print(sentence_keywords)\n",
    "        for sentence_keyword in sentence_keywords:\n",
    "            best = None\n",
    "            match = None\n",
    "            for student_keyword in student_keywords:\n",
    "                sim = sentence_similarity(sentence_keyword, student_keyword)\n",
    "                if best is None:\n",
    "                    best = sim\n",
    "                    match = student_keyword\n",
    "                elif sim<best:\n",
    "                    best = sim\n",
    "                    match = student_keyword\n",
    "            if best != math.inf:\n",
    "                sum += best\n",
    "#                 print(sentence_keyword,\",\",match,\",\", best)\n",
    "        if round(sum/len(sentence_keywords),1) <= 1:\n",
    "            marks += model_answer[sentence]\n",
    "    print(marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for student_answer,model_answer in zip(answers1,model_answer_list):\n",
    "    print(\"Student -\\n\",student_answer, \"\\nModel answer\\n\",''.join(model_answer.keys()))\n",
    "    evaluate(student_answer, model_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['very/RB', 'economical/JJ', 'idea/NN']"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.utils import lemmatize\n",
    "lemmatized_sentence = [word.decode('utf-8').split('.')[0] for word in lemmatize(\"very economical idea\")]\n",
    "lemmatized_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(1.03333,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
