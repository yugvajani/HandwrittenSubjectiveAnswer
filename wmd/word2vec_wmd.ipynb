{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://medium.com/@tarekseif0/document-similarity-using-word-movers-distance-and-cosine-similarity-d698ad435422"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "import json\n",
    "from rake_nltk import Rake\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk import word_tokenize, pos_tag\n",
    "from pyemd import emd\n",
    "# from gensim.similarities import WmdSimilarity\n",
    "\n",
    "\n",
    "# Load pretrained model (since intermediate data is not included, the model cannot be refined with additional data)\n",
    "# model = Word2Vec.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True, norm_only=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin.gz', binary=True) #without *norm_only* param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dog = model['dog']\n",
    "# print(dog.shape)\n",
    "# print(dog[:10])\n",
    "\n",
    "# # Deal with an out of dictionary word: Михаил (Michail)\n",
    "# # if 'Михаил' in model:\n",
    "# #     print(model['Михаил'].shape)\n",
    "# # else:\n",
    "# #     print('{0} is an out of dictionary word'.format('Михаил'))\n",
    "\n",
    "# # Some predefined functions that show content related information for given words\n",
    "# print(model.most_similar(positive=['woman', 'king'], negative=['man']))\n",
    "\n",
    "# # print(model.doesnt_match(\"breakfast cereal dinner lunch\".split()))\n",
    "\n",
    "# # print(model.similarity('woman', 'man'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers1 = []\n",
    "f = open('answers1.txt')\n",
    "lines = f.readlines()\n",
    "\n",
    "for line in lines:\n",
    "    if line!='\\n':\n",
    "        answers1 += [line.replace('\\n', '')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data type before reconstruction :  <class 'str'>\n",
      "Data type after reconstruction :  <class 'list'>\n"
     ]
    }
   ],
   "source": [
    "with open('model_answers.txt') as f: \n",
    "    data = f.read() \n",
    "  \n",
    "print(\"Data type before reconstruction : \", type(data)) \n",
    "      \n",
    "# reconstructing the data as a dictionary \n",
    "model_answer_list = json.loads(data) \n",
    "  \n",
    "print(\"Data type after reconstruction : \", type(model_answer_list)) \n",
    "# print(model_answer_list) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'FCFS stands for First Come, First Served.': 0.5, 'It is a type of scheduling algorithm.': 0.5, 'In this scheme, if a process requests the CPU first, it is allocated to the CPU first.': 1, 'Its implementation is managed by a FIFO queue.': 1, 'It is simple and easy to understand & implement.': 1, 'The process with less execution time suffer i.e. waiting time is often quite long.': 1, 'This effect results in lower CPU and device utilization.': 1, 'FCFS algorithm is particularly troublesome for time-sharing systems, where it is important that each user get a share of the CPU at regular intervals.': 1}\n",
      "means first come first served .  It operating Systems scheduling algorithm that automatically executes queued requests and processes in order of their arrival Advantages is that it is simple and easy to understand  Disadvantages is that the process with less execution time suffer that waiting time is often quite lo long is\n"
     ]
    }
   ],
   "source": [
    "model_answer = model_answer_list[2]\n",
    "# student_answer =  answers1[-2]\n",
    "student_answer = \"means first come first served .  It operating Systems scheduling algorithm that automatically executes queued requests and processes in order of their arrival Advantages is that it is simple and easy to understand  Disadvantages is that the process with less execution time suffer that waiting time is often quite lo long is\"\n",
    "\n",
    "print(model_answer)\n",
    "print(student_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def penn_to_wn(tag):\n",
    "    \"\"\" Convert between a Penn Treebank tag to a simplified Wordnet tag \"\"\"\n",
    "    if tag.startswith('N'):\n",
    "        return 'n'\n",
    " \n",
    "    if tag.startswith('V'):\n",
    "        return 'v'\n",
    " \n",
    "    if tag.startswith('J'):\n",
    "        return 'a'\n",
    " \n",
    "    if tag.startswith('R'):\n",
    "        return 'r'\n",
    " \n",
    "    return 'n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_similarity(model_key, student_key):\n",
    "    lemmatizer = WordNetLemmatizer() \n",
    "\n",
    "    model_answer_tokenized = word_tokenize(model_key)\n",
    "    model_pos_tagged = pos_tag(model_answer_tokenized)\n",
    "#     print(model_pos_tagged)\n",
    "    model_tagged = [lemmatizer.lemmatize(word[0].lower(),penn_to_wn(word[1])) for word in model_pos_tagged]\n",
    "\n",
    "    student_answer_tokenized = word_tokenize(student_key)\n",
    "    student_pos_tagged = pos_tag(student_answer_tokenized)\n",
    "#     print(student_pos_tagged)\n",
    "    student_tagged = [lemmatizer.lemmatize(word[0].lower(),penn_to_wn(word[1])) for word in student_pos_tagged]\n",
    "    \n",
    "#     print(model_tagged,student_tagged)\n",
    "    return model.wmdistance(model_tagged, student_tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = Rake()\n",
    "model.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['means first come first served', 'operating systems scheduling algorithm', 'often quite lo long', 'automatically executes queued requests', 'less execution time suffer', 'waiting time', 'understand disadvantages', 'arrival advantages', 'simple', 'processes', 'process', 'order', 'easy']\n"
     ]
    }
   ],
   "source": [
    "r.extract_keywords_from_text(student_answer)\n",
    "student_keywords = r.get_ranked_phrases()\n",
    "print(student_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['first served', 'first come', 'fcfs stands']\n",
      "first served , means first come first served , 0.5138518368579864\n",
      "first come , means first come first served , 0.4880002018068313\n",
      "fcfs stands , waiting time , 1.2559440785826443\n",
      "0.7525987057491541\n",
      "['scheduling algorithm', 'type']\n",
      "scheduling algorithm , operating systems scheduling algorithm , 0.6121213810282647\n",
      "type , simple , 1.2102627754211426\n",
      "0.9111920782247036\n",
      "['process requests', 'cpu first', 'scheme', 'allocated']\n",
      "process requests , processes , 0.6488169431686401\n",
      "cpu first , means first come first served , 0.8189030481029034\n",
      "scheme , processes , 1.2096816301345825\n",
      "allocated , automatically executes queued requests , 1.2844080323064029\n",
      "0.9904524134281323\n",
      "['fifo queue', 'managed', 'implementation']\n",
      "fifo queue , waiting time , 1.1853999471887946\n",
      "managed , easy , 1.2190260887145996\n",
      "implementation , processes , 1.1563019752502441\n",
      "1.1869093370512127\n",
      "['understand', 'simple', 'implement', 'easy']\n",
      "understand , understand disadvantages , 0.6540879011154175\n",
      "simple , simple , 0.0\n",
      "implement , operating systems scheduling algorithm , 1.2382073730850218\n",
      "easy , easy , 0.0\n",
      "0.4730738185501098\n",
      "['less execution time suffer', 'often quite long', 'waiting time', 'process', 'e']\n",
      "less execution time suffer , less execution time suffer , 0.0\n",
      "often quite long , often quite lo long , 0.3404038409206008\n",
      "waiting time , waiting time , 0.0\n",
      "process , processes , 0.0\n",
      "e , processes , 1.3103384971618652\n",
      "0.3301484676164932\n",
      "['lower cpu', 'effect results', 'device utilization']\n",
      "lower cpu , often quite lo long , 1.260659227657616\n",
      "effect results , less execution time suffer , 1.2455472680597006\n",
      "device utilization , operating systems scheduling algorithm , 1.2190455279484986\n",
      "1.2417506745552718\n",
      "['user get', 'sharing systems', 'regular intervals', 'particularly troublesome', 'fcfs algorithm', 'time', 'share', 'important', 'cpu']\n",
      "user get , automatically executes queued requests , 1.216072444213867\n",
      "sharing systems , operating systems scheduling algorithm , 0.9568133464198113\n",
      "regular intervals , waiting time , 1.2647066985088586\n",
      "particularly troublesome , often quite lo long , 1.1751833811430334\n",
      "fcfs algorithm , operating systems scheduling algorithm , 0.9557656954521835\n",
      "time , waiting time , 0.5921280980110168\n",
      "share , means first come first served , 1.322899925023985\n",
      "important , easy , 1.077913761138916\n",
      "cpu , often quite lo long , 1.3106818516999483\n",
      "1.0969072446235133\n"
     ]
    }
   ],
   "source": [
    "for sentence in model_answer.keys():\n",
    "    sum = 0\n",
    "    r.extract_keywords_from_text(sentence)\n",
    "    sentence_keywords = r.get_ranked_phrases()\n",
    "    print(sentence_keywords)\n",
    "#     print(sentence_keyword,\",\",student_keyword,\",\",sentence_similarity(sentence_keyword, student_keyword))\n",
    "    for sentence_keyword in sentence_keywords:\n",
    "        best = None\n",
    "        match = None\n",
    "        for student_keyword in student_keywords:\n",
    "#             print(student_keyword)\n",
    "#             print(lemmatizer.lemmatize([x for x in word_tokenize(sentence_keyword)]))\n",
    "#             print(sentence_keyword,\",\",student_keyword,\",\",sentence_similarity(sentence_keyword, student_keyword))\n",
    "            sim = sentence_similarity(sentence_keyword, student_keyword)\n",
    "            if best is None:\n",
    "                best = sim\n",
    "                match = student_keyword\n",
    "            elif sim<best:\n",
    "                best = sim\n",
    "                match = student_keyword\n",
    "        sum += best\n",
    "        print(sentence_keyword,\",\",match,\",\", best)\n",
    "    print(sum/len(sentence_keywords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from gensim.similarities import WmdSimilarity\n",
    "# lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_best = 10\n",
    "# instance = WmdSimilarity(student_keywords, model, num_best=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for sentence in model_answer.keys():\n",
    "#     r.extract_keywords_from_text(sentence)\n",
    "#     sentence_keywords = r.get_ranked_phrases()\n",
    "#     for sentence_keyword in sentence_keywords:\n",
    "#         sentence_keyword_tokenized = word_tokenize(sentence_keyword)\n",
    "#         sentence_keyword_pos_tagged = pos_tag(sentence_keyword_tokenized)\n",
    "#         sentence_keyword_tagged = [lemmatizer.lemmatize(word[0].lower(),penn_to_wn(word[1])) for word in sentence_keyword_pos_tagged]\n",
    "#         sims = instance[sentence_keyword_tagged]\n",
    "#         print(sentence_keyword_tagged)\n",
    "#         for i in range(len(sims)):\n",
    "#             print ('sim = %.4f' % sims[i][1])\n",
    "#             print(student_keywords[sims[i][0]])\n",
    "# #         for student_keyword in student_keywords:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing average similarity of all answers with one-another"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from gensim.models import Word2Vec\n",
    "# from gensim.models import KeyedVectors\n",
    "# import json\n",
    "# from rake_nltk import Rake\n",
    "# from nltk.stem import WordNetLemmatizer \n",
    "# from nltk import word_tokenize, pos_tag\n",
    "# from pyemd import emd\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin.gz', binary=True) #without *norm_only* param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers1 = []\n",
    "f = open('answers1.txt',encoding='utf-8')\n",
    "lines = f.readlines()\n",
    "\n",
    "for line in lines:\n",
    "    if line!='\\n':\n",
    "        answers1 += [line.replace('\\n', '')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data type before reconstruction :  <class 'str'>\n",
      "Data type after reconstruction :  <class 'list'>\n"
     ]
    }
   ],
   "source": [
    "with open('model_answers.txt') as f: \n",
    "    data = f.read() \n",
    "  \n",
    "print(\"Data type before reconstruction : \", type(data)) \n",
    "      \n",
    "# reconstructing the data as a dictionary \n",
    "model_answer_list = json.loads(data) \n",
    "  \n",
    "print(\"Data type after reconstruction : \", type(model_answer_list)) \n",
    "# print(model_answer_list) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def penn_to_wn(tag):\n",
    "    \"\"\" Convert between a Penn Treebank tag to a simplified Wordnet tag \"\"\"\n",
    "    if tag.startswith('N'):\n",
    "        return 'n'\n",
    " \n",
    "    if tag.startswith('V'):\n",
    "        return 'v'\n",
    " \n",
    "    if tag.startswith('J'):\n",
    "        return 'a'\n",
    " \n",
    "    if tag.startswith('R'):\n",
    "        return 'r'\n",
    " \n",
    "    return 'n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_similarity(model_key, student_key):\n",
    "    lemmatizer = WordNetLemmatizer() \n",
    "\n",
    "    model_answer_tokenized = word_tokenize(model_key)\n",
    "    model_pos_tagged = pos_tag(model_answer_tokenized)\n",
    "    model_tagged = [lemmatizer.lemmatize(word[0].lower(),penn_to_wn(word[1])) for word in model_pos_tagged]\n",
    "\n",
    "    student_answer_tokenized = word_tokenize(student_key)\n",
    "    student_pos_tagged = pos_tag(student_answer_tokenized)\n",
    "    student_tagged = [lemmatizer.lemmatize(word[0].lower(),penn_to_wn(word[1])) for word in student_pos_tagged]\n",
    "    \n",
    "#     print(model_tagged,student_tagged)\n",
    "    return model.wmdistance(model_tagged, student_tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = Rake()\n",
    "# model.init_sims(replace=True)\n",
    "# model = Word2Vec.load(\"word2vec.model\")\n",
    "model = KeyedVectors.load(\"word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(student_answer, model_answer):\n",
    "    r.extract_keywords_from_text(student_answer)\n",
    "    student_keywords = r.get_ranked_phrases()\n",
    "#     print(student_keywords)\n",
    "    marks = 0\n",
    "    for sentence in model_answer.keys():\n",
    "        sum = 0\n",
    "        r.extract_keywords_from_text(sentence)\n",
    "        sentence_keywords = r.get_ranked_phrases()\n",
    "#         print(sentence_keywords)\n",
    "        for sentence_keyword in sentence_keywords:\n",
    "            best = None\n",
    "            match = None\n",
    "            for student_keyword in student_keywords:\n",
    "                sim = sentence_similarity(sentence_keyword, student_keyword)\n",
    "                if best is None:\n",
    "                    best = sim\n",
    "                    match = student_keyword\n",
    "                elif sim<best:\n",
    "                    best = sim\n",
    "                    match = student_keyword\n",
    "            if best != math.inf:\n",
    "                sum += best\n",
    "#                 print(sentence_keyword,\",\",match,\",\", best)\n",
    "        if round(sum/len(sentence_keywords),1) <= 1:\n",
    "            marks += model_answer[sentence]\n",
    "        elif round(sum/len(sentence_keywords),1) > 1 and round(sum/len(sentence_keywords),1) <= 1.1:\n",
    "            marks += model_answer[sentence] * 0.5\n",
    "    print(marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student -\n",
      " Operating system main purpose is to manage all resources of hardware and software that are connect with computer. Without operating system all computer system are helpless, because operating system create the interface between user and hardware. \n",
      "Model answer\n",
      " It is designed to make sure that a computer system performs well by managing its computational activities.It provides an environment for the development and execution of programs.\n",
      "1\n",
      "Student -\n",
      " Mutual Exclusion is where a resource can be held by only one process at a time. Hold and Wait is where a process can hold a number of resources at a time and at the same time, it can request for other resources that are being held by some other process. No preemption is where a resource can't be preempted from the process by another process, forcefully.  Circular wait is a condition when the first process is waiting for the resource held by the second process, the second process is waiting for the resource held by the third process, and so on.  \n",
      "Model answer\n",
      " Mutual Exclusion Condition: It specifies that the resources involved are non-sharable.Hold and Wait Condition: It specifies that there must be a process that is holding a resource already allocated to it while waiting for additional resource that are currently being held by other processes.No-Preemptive Condition: Resources cannot be taken away while they are being used by processes.Circular Wait Condition: It is an explanation of the second condition. It specifies that the processes in the system form a circular list or a chain where each process in the chain is waiting for a resource held by next process in the chain.\n",
      "4\n",
      "Student -\n",
      " FCFS means First Come First Served. It is an operating system scheduling algorithm that automatically executes queued requests and processes in order of their arrival. Advantages is that it is simple and easy to understand. Disadvantages is that the process with less execution time suffer that is waiting time is often quite long. \n",
      "Model answer\n",
      " FCFS stands for First Come, First Served.It is a type of scheduling algorithm.In this scheme, if a process requests the CPU first, it is allocated to the CPU first.Its implementation is managed by a FIFO queue.It is simple and easy to understand & implement.The process with less execution time suffer i.e. waiting time is often quite long.This effect results in lower CPU and device utilization.FCFS algorithm is particularly troublesome for time-sharing systems, where it is important that each user get a share of the CPU at regular intervals.\n",
      "4.5\n",
      "Student -\n",
      " It is a banker algorithm used to avoid deadlock and allocate resources safely to each process in the computer system.  The banker's algorithm is named because it checks whether a person should be sanctioned a loan amount or not to help the bank system safely simulate allocation resources.  \n",
      "Model answer\n",
      " Banker's algorithm is used to avoid deadlock. It is the one of deadlock-avoidance method.It is named as Banker's algorithm on the banking system where bank never allocates available cash in such a manner that it can no longer satisfy the requirements of all of its customers.\n",
      "2\n",
      "Student -\n",
      " There are two types of fragmentation in OS which are given as: Internal fragmentation, and External fragmentation. Internal fragmentation happens when the memory is split into mounted sized blocks. External fragmentation happens when there's a sufficient quantity of area within the memory to satisfy the memory request of a method. \n",
      "Model answer\n",
      " Internal fragmentation: It is occurred when we deal with the systems that have fixed size allocation units.External fragmentation: It is occurred when we deal with systems that have variable-size allocation units.\n",
      "2\n",
      "Student -\n",
      " Spooling is a process in which data is temporarily held to be used and executed by a device, program or the system. Data is sent to and stored in memory or other volatile storage until the program or computer requests it for execution. \n",
      "Model answer\n",
      " Spooling is a process in which data is temporarily gathered to be used and executed by a device, program or the system.It is associated with printing. When different applications send output to the printer at the same time, spooling keeps these all jobs into a disk file and queues them accordingly to the printer.\n",
      "1\n",
      "Student -\n",
      " A semaphore is a signaling mechanism, and a thread that is waiting on a semaphore can be signaled by another thread. There are two types of semaphore. Binary Semaphore and Count Semaphore \n",
      "Model answer\n",
      " Semaphore is a protected variable or abstract data type that is used to lock the resource being used.The value of the semaphore indicates the status of a common resource.Binary semaphores Counting semaphores\n",
      "2\n",
      "Student -\n",
      " Generally, on increasing the number of frames to a process' virtual memory, its execution becomes faster as less number of page faults occur. Sometimes the reverse happens, i.e. more number of page faults occur when more frames are allocated to a process. This most unexpected result is termed as Belady's Anomaly. Belady's anomaly is the name given to the phenomenon where increasing the number of page frames results in an increase in the number of page faults for a given memory access pattern. \n",
      "Model answer\n",
      " Belady's Anomaly is also called FIFO anomaly.Usually, on increasing the number of frames allocated to a process virtual memory, the process execution is faster, because fewer page faults occur. Sometimes, the reverse happens, i.e., the execution time increases even when more frames are allocated to the process. This is Belady's Anomaly. This is true for certain page reference patterns.\n",
      "2\n",
      "Student -\n",
      " Responsiveness, Resource Sharing, Economy, Scalability \n",
      "Model answer\n",
      " Enhance the responsiveness to the users.Resource sharing within the process.EconomicalCompletely utilize the multiprocessing architecture.\n",
      "1.0\n",
      "Student -\n",
      " Running, Waiting, Ready, New, Terminate \n",
      "Model answer\n",
      " New ProcessRunning ProcessWaiting ProcessReady ProcessTerminated Process\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "for student_answer,model_answer in zip(answers1,model_answer_list):\n",
    "    print(\"Student -\\n\",student_answer, \"\\nModel answer\\n\",''.join(model_answer.keys()))\n",
    "    evaluate(student_answer, model_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.utils import lemmatize\n",
    "lemmatized_sentence = [word.decode('utf-8').split('.')[0] for word in lemmatize(\"very economical idea\")]\n",
    "lemmatized_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(1.09,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\users\\sarika\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (3.8.3)\n",
      "Requirement already satisfied: numpy>=1.11.3 in c:\\users\\sarika\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from gensim) (1.20.1)\n",
      "Requirement already satisfied: scipy>=0.18.1 in c:\\users\\sarika\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from gensim) (1.6.1)\n",
      "Requirement already satisfied: six>=1.5.0 in c:\\users\\sarika\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from gensim) (1.15.0)\n",
      "Requirement already satisfied: smart_open>=1.8.1 in c:\\users\\sarika\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from gensim) (4.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install --upgrade gensim --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
